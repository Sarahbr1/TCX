{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2236708,"sourceType":"datasetVersion","datasetId":1343913},{"sourceId":7343678,"sourceType":"datasetVersion","datasetId":4264103},{"sourceId":7344862,"sourceType":"datasetVersion","datasetId":4264904}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <b> Convolutional Neural Network for Brain Tumor Detection and Diagnosis ","metadata":{}},{"cell_type":"code","source":"!pip install split-folders\n!pip install torch-summary","metadata":{"papermill":{"duration":11.048635,"end_time":"2022-12-25T14:49:51.627145","exception":false,"start_time":"2022-12-25T14:49:40.57851","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:02.019152Z","iopub.execute_input":"2024-01-05T15:10:02.019644Z","iopub.status.idle":"2024-01-05T15:10:05.858897Z","shell.execute_reply.started":"2024-01-05T15:10:02.019603Z","shell.execute_reply":"2024-01-05T15:10:05.857596Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Requirement already satisfied: split-folders in /opt/conda/lib/python3.10/site-packages (0.5.1)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m^C\nTraceback (most recent call last):\n  File \"/opt/conda/bin/pip\", line 6, in <module>\n    from pip._internal.cli.main import main\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n    from pip._internal.cli.autocompletion import autocomplete\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n    from pip._internal.cli.main_parser import create_main_parser\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n    from pip._internal.build_env import get_runnable_pip\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/build_env.py\", line 19, in <module>\n    from pip._internal.cli.spinners import open_spinner\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n    from pip._internal.utils.logging import get_indentation\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 29, in <module>\n    from pip._internal.utils.misc import ensure_dir\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/utils/misc.py\", line 40, in <module>\n    from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/tenacity/__init__.py\", line 548, in <module>\n    from pip._vendor.tenacity._asyncio import AsyncRetrying  # noqa:E402,I100\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/tenacity/_asyncio.py\", line 21, in <module>\n    from asyncio import sleep\n  File \"/opt/conda/lib/python3.10/asyncio/__init__.py\", line 8, in <module>\n    from .base_events import *\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 40, in <module>\n    from . import events\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 14, in <module>\n    import contextvars\n  File \"/opt/conda/lib/python3.10/contextvars.py\", line 1, in <module>\n    from _contextvars import Context, ContextVar, Token, copy_context\nKeyboardInterrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import essential libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set(style='darkgrid')\nimport copy # A module that provides functions for creating copies of objects, useful for avoiding unintended modifications to variables.\nimport os # A module that provides a way to interact with the operating system, allowing for tasks such as file and directory manipulation.\nimport torch\nfrom PIL import Image # A module from the Python Imaging Library (PIL) that provides functionality for opening, manipulating, and saving various image file formats.\nfrom torch.utils.data import Dataset # A PyTorch class that represents a dataset and provides an interface for accessing and processing the data during training.\nimport torchvision\nimport torchvision.transforms as transforms # A module from the torchvision library that provides common image transformations, such as resizing, cropping, and normalization.\nfrom torch.utils.data import random_split # A function from PyTorch that allows for randomly splitting a dataset into training and validation subsets.\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau # A PyTorch scheduler that adjusts the learning rate during training based on a specified metric, reducing it when the metric plateaus.\nimport torch.nn as nn # A module in PyTorch that provides classes for defining and building neural networks.\nfrom torchvision import utils # A module from torchvision that contains utility functions for working with images, such as saving and visualizing them.\nfrom torchvision.datasets import ImageFolder\nimport splitfolders\nfrom torchsummary import summary\nimport torch.nn.functional as F\nimport pathlib\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools # This import statement imports the itertools module, which provides functions for efficient looping and combining of iterables. It can be used for tasks such as generating combinations or permutations of elements.\nfrom tqdm.notebook import trange, tqdm # These functions allow for the creation of progress bars to track the progress of loops or tasks.\nfrom torch import optim\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":2.009705,"end_time":"2022-12-25T14:49:40.56405","exception":false,"start_time":"2022-12-25T14:49:38.554345","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:05.861885Z","iopub.execute_input":"2024-01-05T15:10:05.862249Z","iopub.status.idle":"2024-01-05T15:10:05.875462Z","shell.execute_reply.started":"2024-01-05T15:10:05.862219Z","shell.execute_reply":"2024-01-05T15:10:05.874295Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"from IPython.core.display import display, HTML, Javascript\n\ncolor_map = ['#FFFFFF','#FF5733']\n\nprompt = color_map[-1]\nmain_color = color_map[0]\nstrong_main_color = color_map[1]\ncustom_colors = [strong_main_color, main_color]\n\ncss_file = '''\ndiv #notebook {\nbackground-color: white;\nline-height: 20px;\n}\n\n#notebook-container {\n%s\nmargin-top: 2em;\npadding-top: 2em;\nborder-top: 4px solid %s;\n-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n}\n\ndiv .input {\nmargin-bottom: 1em;\n}\n\n.rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\ncolor: %s;\nfont-weight: 600;\n}\n\ndiv.input_area {\nborder: none;\n    background-color: %s;\n    border-top: 2px solid %s;\n}\n\ndiv.input_prompt {\ncolor: %s;\n}\n\ndiv.output_prompt {\ncolor: %s; \n}\n\ndiv.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\nbackground: %s;\n}\n\ndiv.cell.selected, div.cell.selected.jupyter-soft-selected {\n    border-color: %s;\n}\n\n.edit_mode div.cell.selected:before {\nbackground: %s;\n}\n\n.edit_mode div.cell.selected {\nborder-color: %s;\n\n}\n'''\n\ndef to_rgb(h): \n    return tuple(int(h[i:i+2], 16) for i in [0, 2, 4])\n\nmain_color_rgba = 'rgba(%s, %s, %s, 0.1)' % (to_rgb(main_color[1:]))\nopen('notebook.css', 'w').write(css_file % ('width: 95%;', main_color, main_color, main_color_rgba, \n                                            main_color,  main_color, prompt, main_color, main_color, \n                                            main_color, main_color))\n\ndef nb(): \n    return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\nnb()\n","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.030458,"end_time":"2022-12-25T14:49:51.670755","exception":false,"start_time":"2022-12-25T14:49:51.640297","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:05.877068Z","iopub.execute_input":"2024-01-05T15:10:05.877478Z","iopub.status.idle":"2024-01-05T15:10:05.895548Z","shell.execute_reply.started":"2024-01-05T15:10:05.877443Z","shell.execute_reply":"2024-01-05T15:10:05.894404Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\ndiv #notebook {\nbackground-color: white;\nline-height: 20px;\n}\n\n#notebook-container {\nwidth: 95%;\nmargin-top: 2em;\npadding-top: 2em;\nborder-top: 4px solid #FFFFFF;\n-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n}\n\ndiv .input {\nmargin-bottom: 1em;\n}\n\n.rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\ncolor: #FFFFFF;\nfont-weight: 600;\n}\n\ndiv.input_area {\nborder: none;\n    background-color: rgba(255, 255, 255, 0.1);\n    border-top: 2px solid #FFFFFF;\n}\n\ndiv.input_prompt {\ncolor: #FFFFFF;\n}\n\ndiv.output_prompt {\ncolor: #FF5733; \n}\n\ndiv.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\nbackground: #FFFFFF;\n}\n\ndiv.cell.selected, div.cell.selected.jupyter-soft-selected {\n    border-color: #FFFFFF;\n}\n\n.edit_mode div.cell.selected:before {\nbackground: #FFFFFF;\n}\n\n.edit_mode div.cell.selected {\nborder-color: #FFFFFF;\n\n}\n</style>"},"metadata":{}}]},{"cell_type":"markdown","source":"## <b>1 <span style='color:#e61227'>|</span> Dataset</b> \n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#03112A;font-size:150%;\n            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>1.1 |</span></b> Load Dataset</b></p>\n</div>","metadata":{"papermill":{"duration":0.012458,"end_time":"2022-12-25T14:49:51.822418","exception":false,"start_time":"2022-12-25T14:49:51.80996","status":"completed"},"tags":[]}},{"cell_type":"code","source":"labels_df = pd.read_csv('/kaggle/input/brian-tumor-dataset/metadata.csv')\nprint(labels_df.head().to_markdown())","metadata":{"papermill":{"duration":0.614551,"end_time":"2022-12-25T14:49:52.44957","exception":false,"start_time":"2022-12-25T14:49:51.835019","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:05.897065Z","iopub.execute_input":"2024-01-05T15:10:05.897480Z","iopub.status.idle":"2024-01-05T15:10:05.927610Z","shell.execute_reply.started":"2024-01-05T15:10:05.897446Z","shell.execute_reply":"2024-01-05T15:10:05.926561Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"|    |   Unnamed: 0 | image           | class   | format   | mode   | shape         |\n|---:|-------------:|:----------------|:--------|:---------|:-------|:--------------|\n|  0 |            0 | Cancer (1).jpg  | tumor   | JPEG     | RGB    | (512, 512, 3) |\n|  1 |            1 | Cancer (1).png  | tumor   | PNG      | L      | (300, 240)    |\n|  2 |            2 | Cancer (1).tif  | tumor   | TIFF     | RGB    | (256, 256, 3) |\n|  3 |            3 | Cancer (10).jpg | tumor   | JPEG     | RGB    | (512, 512, 3) |\n|  4 |            4 | Cancer (10).tif | tumor   | TIFF     | RGB    | (256, 256, 3) |\n","output_type":"stream"}]},{"cell_type":"code","source":"os.listdir('/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set')","metadata":{"papermill":{"duration":0.023499,"end_time":"2022-12-25T14:49:52.486395","exception":false,"start_time":"2022-12-25T14:49:52.462896","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:05.931213Z","iopub.execute_input":"2024-01-05T15:10:05.931570Z","iopub.status.idle":"2024-01-05T15:10:05.938976Z","shell.execute_reply.started":"2024-01-05T15:10:05.931542Z","shell.execute_reply":"2024-01-05T15:10:05.938007Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"['Brain Tumor', 'Healthy']"},"metadata":{}}]},{"cell_type":"code","source":"labels_df.shape","metadata":{"papermill":{"duration":0.021089,"end_time":"2022-12-25T14:49:52.520259","exception":false,"start_time":"2022-12-25T14:49:52.49917","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:05.940209Z","iopub.execute_input":"2024-01-05T15:10:05.940639Z","iopub.status.idle":"2024-01-05T15:10:05.948745Z","shell.execute_reply.started":"2024-01-05T15:10:05.940604Z","shell.execute_reply":"2024-01-05T15:10:05.947851Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"(4600, 6)"},"metadata":{}}]},{"cell_type":"markdown","source":"## <b>3 <span style='color:#e61227'>|</span> Data Preparation </b> \n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#03112A;font-size:150%;\n            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>3.1 |</span></b> Splitting Dataset</b></p>\n</div>\n\n- We need to evaluate the model on validation datasets to track the model's performance during training. Then, Let's use 20% of the dataset for the **Validation set** and use the rest as the **Training set**, so we have an **80/20** split!","metadata":{"papermill":{"duration":0.035324,"end_time":"2022-12-25T14:50:13.460476","exception":false,"start_time":"2022-12-25T14:50:13.425152","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Dataset Path\ndata_dir = '/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set'\ndata_dir = pathlib.Path(data_dir)\n\n# Splitting dataset into train, val, and test sets\nsplitfolders.ratio(data_dir, output='brain', seed=20, ratio=(0.7, 0.1, 0.2))\n\n# New dataset paths\ndata_dir = '/kaggle/working/brain'\ndata_dir = pathlib.Path(data_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:05.949983Z","iopub.execute_input":"2024-01-05T15:10:05.950382Z","iopub.status.idle":"2024-01-05T15:10:06.431974Z","shell.execute_reply.started":"2024-01-05T15:10:05.950345Z","shell.execute_reply":"2024-01-05T15:10:06.428870Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stderr","text":"\nCopying files: 0 files [00:00, ? files/s]\u001b[A","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(data_dir)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Splitting dataset into train, val, and test sets\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msplitfolders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# New dataset paths\u001b[39;00m\n\u001b[1;32m      9\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/brain\u001b[39m\u001b[38;5;124m'\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/splitfolders/split.py:87\u001b[0m, in \u001b[0;36mratio\u001b[0;34m(input, output, seed, ratio, group_prefix, move)\u001b[0m\n\u001b[1;32m     84\u001b[0m     prog_bar \u001b[38;5;241m=\u001b[39m tqdm(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopying files\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_dir \u001b[38;5;129;01min\u001b[39;00m list_dirs(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 87\u001b[0m     \u001b[43msplit_class_dir_ratio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmove\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_tqdm:\n\u001b[1;32m     98\u001b[0m     prog_bar\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/splitfolders/split.py:233\u001b[0m, in \u001b[0;36msplit_class_dir_ratio\u001b[0;34m(class_dir, output, ratio, seed, prog_bar, group_prefix, move)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_class_dir_ratio\u001b[39m(class_dir, output, ratio, seed, prog_bar, group_prefix, move):\n\u001b[1;32m    230\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    Splits a class folder\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43msetup_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# the data was shuffled already\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     split_train_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(ratio[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(files))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/splitfolders/split.py:219\u001b[0m, in \u001b[0;36msetup_files\u001b[0;34m(class_dir, seed, group_prefix)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03mReturns shuffeld list of filenames\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(seed)  \u001b[38;5;66;03m# make sure its reproducible\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mlist_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group_prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     files \u001b[38;5;241m=\u001b[39m group_by_prefix(files, group_prefix)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/splitfolders/utils.py:15\u001b[0m, in \u001b[0;36mlist_files\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_files\u001b[39m(directory):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Returns all files in a given directory\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     16\u001b[0m         f\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Path(directory)\u001b[38;5;241m.\u001b[39miterdir()\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mis_file() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/splitfolders/utils.py:18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_files\u001b[39m(directory):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Returns all files in a given directory\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     16\u001b[0m         f\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Path(directory)\u001b[38;5;241m.\u001b[39miterdir()\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1322\u001b[0m, in \u001b[0;36mPath.is_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03mWhether this path is a regular file (also True for symlinks pointing\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;124;03mto regular files).\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m S_ISREG(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_mode)\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ignore_error(e):\n","File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1097\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;124;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;124;03m    os.stat() does.\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## <b>4 <span style='color:#e61227'>|</span> Image Augmentation Definitions</b> ","metadata":{"papermill":{"duration":0.043602,"end_time":"2022-12-25T14:50:17.70179","exception":false,"start_time":"2022-12-25T14:50:17.658188","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# define transformation\ntransform = transforms.Compose(\n    [\n        transforms.Resize((256,256)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomRotation(30),\n        transforms.ToTensor(),\n        transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n   ]\n)","metadata":{"papermill":{"duration":0.052413,"end_time":"2022-12-25T14:50:17.797638","exception":false,"start_time":"2022-12-25T14:50:17.745225","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.432853Z","iopub.status.idle":"2024-01-05T15:10:06.433263Z","shell.execute_reply.started":"2024-01-05T15:10:06.433063Z","shell.execute_reply":"2024-01-05T15:10:06.433081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define an object of the custom dataset for the train, validation and test\ntrain_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"train\"), transform=transform) \ntrain_set.transform\nval_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"val\"), transform=transform)\nval_set.transform\ntest_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"test\"), transform=transform)\ntest_set.transform","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.435548Z","iopub.status.idle":"2024-01-05T15:10:06.436045Z","shell.execute_reply.started":"2024-01-05T15:10:06.435835Z","shell.execute_reply":"2024-01-05T15:10:06.435855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualiztion some images from Train Set\nCLA_label = {\n    0 : 'Brain Tumor',\n    1 : 'Healthy'\n} \nfigure = plt.figure(figsize=(10, 10))\ncols, rows = 4, 4\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n    img, label = train_set[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(CLA_label[label])\n    plt.axis(\"off\")\n    img_np = img.numpy().transpose((1, 2, 0))\n    # Clip pixel values to [0, 1]\n    img_valid_range = np.clip(img_np, 0, 1)\n    plt.imshow(img_valid_range)\n    plt.suptitle('Brain Images', y=0.95)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.437777Z","iopub.status.idle":"2024-01-05T15:10:06.438204Z","shell.execute_reply.started":"2024-01-05T15:10:06.438019Z","shell.execute_reply":"2024-01-05T15:10:06.438037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>5 <span style='color:#e61227'>|</span> Creating Dataloaders</b> ","metadata":{"papermill":{"duration":0.044772,"end_time":"2022-12-25T14:50:18.077217","exception":false,"start_time":"2022-12-25T14:50:18.032445","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# import and load train, validation and test\nbatch_size = 64\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 2)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = True, num_workers = 2)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n","metadata":{"papermill":{"duration":0.057816,"end_time":"2022-12-25T14:50:18.183736","exception":false,"start_time":"2022-12-25T14:50:18.12592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.439435Z","iopub.status.idle":"2024-01-05T15:10:06.439825Z","shell.execute_reply.started":"2024-01-05T15:10:06.439627Z","shell.execute_reply":"2024-01-05T15:10:06.439644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print shape for Training data and Validation data and test data\nfor key, value in {'Training data': train_loader, \"Validation data\": val_loader, \"Test data\" : test_loader}.items():\n    for X, y in value:\n        print(f\"{key}:\")\n        print(f\"Shape of X : {X.shape}\")\n        print(f\"Shape of y: {y.shape} {y.dtype}\\n\")\n        break","metadata":{"papermill":{"duration":0.301361,"end_time":"2022-12-25T14:50:18.530596","exception":false,"start_time":"2022-12-25T14:50:18.229235","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.441643Z","iopub.status.idle":"2024-01-05T15:10:06.442205Z","shell.execute_reply.started":"2024-01-05T15:10:06.441931Z","shell.execute_reply":"2024-01-05T15:10:06.441957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>6 <span style='color:#e61227'>|</span> Define Brain Tumor Classifier</b> \n","metadata":{"papermill":{"duration":0.04387,"end_time":"2022-12-25T14:50:18.619294","exception":false,"start_time":"2022-12-25T14:50:18.575424","status":"completed"},"tags":[]}},{"cell_type":"code","source":"'''This function can be useful in determining the output size of a convolutional layer in a neural network,\ngiven the input dimensions and the convolutional layer's parameters.'''\n\ndef findConv2dOutShape(hin,win,conv,pool=2):\n    # get conv arguments\n    kernel_size = conv.kernel_size\n    stride=conv.stride\n    padding=conv.padding\n    dilation=conv.dilation\n\n    hout=np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n\n    if pool:\n        hout/=pool\n        wout/=pool\n    return int(hout),int(wout)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.444057Z","iopub.status.idle":"2024-01-05T15:10:06.444597Z","shell.execute_reply.started":"2024-01-05T15:10:06.444303Z","shell.execute_reply":"2024-01-05T15:10:06.444336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Architecture For CNN_TUMOR Model\nclass CNN_TUMOR(nn.Module):\n    \n    # Network Initialisation\n    def __init__(self, params):\n        \n        super(CNN_TUMOR, self).__init__()\n    \n        Cin,Hin,Win = params[\"shape_in\"]\n        init_f = params[\"initial_filters\"] \n        num_fc1 = params[\"num_fc1\"]  \n        num_classes = params[\"num_classes\"] \n        self.dropout_rate = params[\"dropout_rate\"] \n        \n        # Convolution Layers\n        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n        h,w=findConv2dOutShape(Hin,Win,self.conv1)\n        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n        h,w=findConv2dOutShape(h,w,self.conv2)\n        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n        h,w=findConv2dOutShape(h,w,self.conv3)\n        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n        h,w=findConv2dOutShape(h,w,self.conv4)\n        \n        # compute the flatten size\n        self.num_flatten=h*w*8*init_f\n        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n        self.fc2 = nn.Linear(num_fc1, num_classes)\n\n    def forward(self,X):\n        \n        # Convolution & Pool Layers\n        X = F.relu(self.conv1(X)); \n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv2(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv3(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv4(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = X.view(-1, self.num_flatten)\n        X = F.relu(self.fc1(X))\n        X = F.dropout(X, self.dropout_rate)\n        X = self.fc2(X)\n        return F.log_softmax(X, dim=1)","metadata":{"_kg_hide-input":false,"papermill":{"duration":0.061676,"end_time":"2022-12-25T14:50:18.724104","exception":false,"start_time":"2022-12-25T14:50:18.662428","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.446835Z","iopub.status.idle":"2024-01-05T15:10:06.447406Z","shell.execute_reply.started":"2024-01-05T15:10:06.447115Z","shell.execute_reply":"2024-01-05T15:10:06.447141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_model={\n        \"shape_in\": (3,256,256), \n        \"initial_filters\": 8,    \n        \"num_fc1\": 100,\n        \"dropout_rate\": 0.25,\n        \"num_classes\": 2}\n\n# Create instantiation of Network class\ncnn_model = CNN_TUMOR(params_model)\n\n# define computation hardware approach (GPU/CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = cnn_model.to(device)","metadata":{"papermill":{"duration":3.280473,"end_time":"2022-12-25T14:50:22.047812","exception":false,"start_time":"2022-12-25T14:50:18.767339","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.449093Z","iopub.status.idle":"2024-01-05T15:10:06.449470Z","shell.execute_reply.started":"2024-01-05T15:10:06.449289Z","shell.execute_reply":"2024-01-05T15:10:06.449306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Summary for CNN Model\nsummary(cnn_model, input_size=(3, 256, 256),device=device.type)","metadata":{"papermill":{"duration":6.046363,"end_time":"2022-12-25T14:50:28.138838","exception":false,"start_time":"2022-12-25T14:50:22.092475","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.451443Z","iopub.status.idle":"2024-01-05T15:10:06.452001Z","shell.execute_reply.started":"2024-01-05T15:10:06.451706Z","shell.execute_reply":"2024-01-05T15:10:06.451732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>7 <span style='color:#e61227'>|</span> Loss Function Definition</b> ","metadata":{"papermill":{"duration":0.043415,"end_time":"2022-12-25T14:50:28.227288","exception":false,"start_time":"2022-12-25T14:50:28.183873","status":"completed"},"tags":[]}},{"cell_type":"code","source":"loss_func = nn.NLLLoss(reduction=\"sum\")","metadata":{"papermill":{"duration":0.051641,"end_time":"2022-12-25T14:50:28.322844","exception":false,"start_time":"2022-12-25T14:50:28.271203","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.453264Z","iopub.status.idle":"2024-01-05T15:10:06.453791Z","shell.execute_reply.started":"2024-01-05T15:10:06.453529Z","shell.execute_reply":"2024-01-05T15:10:06.453554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>8 <span style='color:#e61227'>|</span> Optimiser Definition</b> ","metadata":{"papermill":{"duration":0.043081,"end_time":"2022-12-25T14:50:28.409411","exception":false,"start_time":"2022-12-25T14:50:28.36633","status":"completed"},"tags":[]}},{"cell_type":"code","source":"opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\nlr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)","metadata":{"papermill":{"duration":0.052279,"end_time":"2022-12-25T14:50:28.504879","exception":false,"start_time":"2022-12-25T14:50:28.4526","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.455580Z","iopub.status.idle":"2024-01-05T15:10:06.456082Z","shell.execute_reply.started":"2024-01-05T15:10:06.455859Z","shell.execute_reply":"2024-01-05T15:10:06.455889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>9 <span style='color:#e61227'>|</span> Training Model</b> ","metadata":{"papermill":{"duration":0.0434,"end_time":"2022-12-25T14:50:28.591572","exception":false,"start_time":"2022-12-25T14:50:28.548172","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Function to get the learning rate\ndef get_lr(opt):\n    for param_group in opt.param_groups:\n        return param_group['lr']\n\n# Function to compute the loss value per batch of data\ndef loss_batch(loss_func, output, target, opt=None):\n    \n    loss = loss_func(output, target) # get loss\n    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n    \n    if opt is not None:\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    return loss.item(), metric_b\n\n# Compute the loss value & performance metric for the entire dataset (epoch)\ndef loss_epoch(model,loss_func,dataset_dl,opt=None):\n    \n    run_loss=0.0 \n    t_metric=0.0\n    len_data=len(dataset_dl.dataset)\n\n    # internal loop over dataset\n    for xb, yb in dataset_dl:\n        # move batch to device\n        xb=xb.to(device)\n        yb=yb.to(device)\n        output=model(xb) # get model output\n        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n        run_loss+=loss_b        # update running loss\n\n        if metric_b is not None: # update running metric\n            t_metric+=metric_b    \n    \n    loss=run_loss/float(len_data)  # average loss value\n    metric=t_metric/float(len_data) # average metric value\n    \n    return loss, metric","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.055553,"end_time":"2022-12-25T14:50:28.690141","exception":false,"start_time":"2022-12-25T14:50:28.634588","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.457219Z","iopub.status.idle":"2024-01-05T15:10:06.459061Z","shell.execute_reply.started":"2024-01-05T15:10:06.457407Z","shell.execute_reply":"2024-01-05T15:10:06.457424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#03112A;font-size:150%;\n            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>9.2 |</span></b> Training Function</b></p>\n</div>\n","metadata":{"papermill":{"duration":0.042867,"end_time":"2022-12-25T14:50:28.870731","exception":false,"start_time":"2022-12-25T14:50:28.827864","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def Train_Val(model, params,verbose=False):\n    \n    # Get the parameters\n    epochs=params[\"epochs\"]\n    loss_func=params[\"f_loss\"]\n    opt=params[\"optimiser\"]\n    train_dl=params[\"train\"]\n    val_dl=params[\"val\"]\n    lr_scheduler=params[\"lr_change\"]\n    weight_path=params[\"weight_path\"]\n    \n    # history of loss values in each epoch\n    loss_history={\"train\": [],\"val\": []} \n    # histroy of metric values in each epoch\n    metric_history={\"train\": [],\"val\": []} \n    # a deep copy of weights for the best performing model\n    best_model_wts = copy.deepcopy(model.state_dict()) \n    # initialize best loss to a large value\n    best_loss=float('inf') \n\n# Train Model n_epochs (the progress of training by printing the epoch number and the associated learning rate. It can be helpful for debugging, monitoring the learning rate schedule, or gaining insights into the training process.) \n    \n    for epoch in tqdm(range(epochs)):\n        \n        # Get the Learning Rate\n        current_lr=get_lr(opt)\n        if(verbose):\n            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\n\n        \n# Train Model Process\n\n        \n        model.train()\n        train_loss, train_metric = loss_epoch(model,loss_func,train_dl,opt)\n\n        # collect losses\n        loss_history[\"train\"].append(train_loss)\n        metric_history[\"train\"].append(train_metric)\n        \n\n# Evaluate Model Process\n\n        \n        model.eval()\n        with torch.no_grad():\n            val_loss, val_metric = loss_epoch(model,loss_func,val_dl)\n        \n        # store best model\n        if(val_loss < best_loss):\n            best_loss = val_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            \n            # store weights into a local file\n            torch.save(model.state_dict(), weight_path)\n            if(verbose):\n                print(\"Copied best model weights!\")\n        \n        # collect loss and metric for validation dataset\n        loss_history[\"val\"].append(val_loss)\n        metric_history[\"val\"].append(val_metric)\n        \n        # learning rate schedule\n        lr_scheduler.step(val_loss)\n        if current_lr != get_lr(opt):\n            if(verbose):\n                print(\"Loading best model weights!\")\n            model.load_state_dict(best_model_wts) \n\n        if(verbose):\n            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n            print(\"-\"*10) \n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n        \n    return model, loss_history, metric_history","metadata":{"papermill":{"duration":0.095856,"end_time":"2022-12-25T14:50:29.009269","exception":false,"start_time":"2022-12-25T14:50:28.913413","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.460505Z","iopub.status.idle":"2024-01-05T15:10:06.460924Z","shell.execute_reply.started":"2024-01-05T15:10:06.460695Z","shell.execute_reply":"2024-01-05T15:10:06.460712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#03112A;font-size:150%;\n            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>9.3 |</span></b> Training Process </b></p>\n</div>","metadata":{"papermill":{"duration":0.04377,"end_time":"2022-12-25T14:50:29.097122","exception":false,"start_time":"2022-12-25T14:50:29.053352","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define various parameters used for training and evaluation of a cnn_model\n\nparams_train={\n \"train\": train_loader,\"val\": val_loader,\n \"epochs\": 60,\n \"optimiser\": optim.Adam(cnn_model.parameters(),lr=3e-4),\n \"lr_change\": ReduceLROnPlateau(opt,\n                                mode='min',\n                                factor=0.5,\n                                patience=20,\n                                verbose=0),\n \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n \"weight_path\": \"weights.pt\",\n}\n\n# train and validate the model\ncnn_model,loss_hist,metric_hist = Train_Val(cnn_model,params_train)","metadata":{"papermill":{"duration":339.54529,"end_time":"2022-12-25T14:56:08.685628","exception":false,"start_time":"2022-12-25T14:50:29.140338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-05T15:10:06.463344Z","iopub.status.idle":"2024-01-05T15:10:06.463708Z","shell.execute_reply.started":"2024-01-05T15:10:06.463531Z","shell.execute_reply":"2024-01-05T15:10:06.463548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>10 <span style='color:#e61227'>|</span> Evaluation Metric Visualization </b> ","metadata":{"papermill":{"duration":0.045473,"end_time":"2022-12-25T14:56:10.029988","exception":false,"start_time":"2022-12-25T14:56:09.984515","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Convergence History Plot\nepochs=params_train[\"epochs\"]\nfig,ax = plt.subplots(1,2,figsize=(12,5))\n\nsns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='Acc_hist[\"train\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='Acc_hist[\"val\"]')","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.465009Z","iopub.status.idle":"2024-01-05T15:10:06.465415Z","shell.execute_reply.started":"2024-01-05T15:10:06.465216Z","shell.execute_reply":"2024-01-05T15:10:06.465235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#03112A;font-size:150%;\n            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>10.2 |</span></b> Confusion_Matrix </b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"# define function For Classification Report\ndef Ture_and_Pred(val_loader, model):\n    i = 0\n    y_true = []\n    y_pred = []\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.numpy()\n        outputs = model(images)\n        _, pred = torch.max(outputs.data, 1)\n        pred = pred.detach().cpu().numpy()\n        \n        y_true = np.append(y_true, labels)\n        y_pred = np.append(y_pred, pred)\n    \n    return y_true, y_pred\n\n\n# check confusion matrix for error analysis\ny_true, y_pred = Ture_and_Pred(val_loader, cnn_model)\n\nprint(classification_report(y_true, y_pred), '\\n\\n')\ncm = confusion_matrix(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.467569Z","iopub.status.idle":"2024-01-05T15:10:06.468077Z","shell.execute_reply.started":"2024-01-05T15:10:06.467787Z","shell.execute_reply":"2024-01-05T15:10:06.467832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix Plotting Function\ndef show_confusion_matrix(cm, CLA_label, title='Confusion matrix', cmap=plt.cm.YlGnBu):\n    plt.figure(figsize=(10,7))\n    plt.grid(False)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(CLA_label))\n\n    plt.xticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()], rotation=45)\n    plt.yticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()])\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, f\"{cm[i,j]}\\n{cm[i,j]/np.sum(cm)*100:.2f}%\", horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.tight_layout()\n    plt.show()\n\nCLA_label = {0: 'Healthy', 1: 'Tumor'}\nshow_confusion_matrix(cm, CLA_label)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.469672Z","iopub.status.idle":"2024-01-05T15:10:06.470086Z","shell.execute_reply.started":"2024-01-05T15:10:06.469890Z","shell.execute_reply":"2024-01-05T15:10:06.469909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>11<span style='color:#e61227'>|</span> Test Prediction </b>","metadata":{}},{"cell_type":"code","source":"# Set the model to evaluation mode\ncnn_model.eval()\n\n# Define the loss function\nloss_function = nn.NLLLoss(reduction=\"sum\")\n\n# Function to compute the loss and metric for the entire test dataset\ndef evaluate_model(model, loss_func, test_dl):\n    model.eval()\n    test_loss = 0.0\n    test_metric = 0.0\n    total_samples = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_dl:\n            inputs = inputs.to(device)  # Move inputs to the device\n            labels = labels.to(device)  # Move labels to the device\n\n            outputs = model(inputs)  # Forward pass\n            test_loss += loss_func(outputs, labels).item()\n\n            _, predicted = torch.max(outputs, 1)\n            test_metric += (predicted == labels).sum().item()\n\n            total_samples += labels.size(0)\n\n    avg_loss = test_loss / total_samples\n    accuracy = test_metric / total_samples\n\n    return avg_loss, accuracy\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = evaluate_model(cnn_model, loss_function, test_loader)\n\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.471994Z","iopub.status.idle":"2024-01-05T15:10:06.472509Z","shell.execute_reply.started":"2024-01-05T15:10:06.472243Z","shell.execute_reply":"2024-01-05T15:10:06.472268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Test Loss', 'Test Accuracy']\nvalues = [test_loss*100, test_accuracy * 100]\n\nplt.figure(figsize=(8, 6))\nplt.bar(labels, values, color=['blue', 'green'])\nplt.ylabel('Values')\nplt.title('Test Loss and Test Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.474124Z","iopub.status.idle":"2024-01-05T15:10:06.474512Z","shell.execute_reply.started":"2024-01-05T15:10:06.474324Z","shell.execute_reply":"2024-01-05T15:10:06.474342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>12<span style='color:#e61227'>|</span> Save Model </b>","metadata":{}},{"cell_type":"code","source":"torch.save(cnn_model, \"Brain_Tumor_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:10:06.476021Z","iopub.status.idle":"2024-01-05T15:10:06.476378Z","shell.execute_reply.started":"2024-01-05T15:10:06.476202Z","shell.execute_reply":"2024-01-05T15:10:06.476219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <b>13<span style='color:#e61227'>|</span> Load Model </b>","metadata":{}},{"cell_type":"code","source":"model = torch.load(\"/kaggle/working/Brain_Tumor_model.pt\")\n\nimport torch\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n# Define your function to predict the class of a single image\ndef predict_image_class(model, image_path, device):\n    # Define transformations to preprocess the image\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # Load and preprocess the image, converting to RGB mode\n    img = Image.open(image_path).convert('RGB')\n    img = transform(img)  # Transform without random flips or rotations\n\n    # Add a batch dimension and move the tensor to the device (CPU or GPU)\n    img = img.unsqueeze(0).to(device)\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Perform inference\n    with torch.no_grad():\n        output = model(img)\n\n    # Get the predicted class index\n    predicted_class = torch.argmax(output, dim=1).item()\n\n    return predicted_class\n\n# Assuming 'model' is already loaded with your CNN model\n# 'device' is either 'cuda' (GPU) or 'cpu'\n\n# Path to the image you want to predict\nimage_path = '/kaggle/input/datasetclear/brainclear.png'  # Replace this with your image path\n\n# Call the predict_image_class function\npredicted_class = predict_image_class(model, image_path, device)\n\n# Display or use the predicted class as needed\nif predicted_class == 1 : print(f\"Brain Tumor\")\nelse : print(f\"Healthy\")\n#print(f\"Predicted class index: {predicted_class}\")\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-05T15:28:47.382979Z","iopub.execute_input":"2024-01-05T15:28:47.383488Z","iopub.status.idle":"2024-01-05T15:28:47.418425Z","shell.execute_reply.started":"2024-01-05T15:28:47.383452Z","shell.execute_reply":"2024-01-05T15:28:47.417318Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Healthy\n","output_type":"stream"}]}]}